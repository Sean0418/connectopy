{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ§  Brain Connectome Analysis - Local Demo\n",
        "\n",
        "This notebook demonstrates the Brain Connectome analysis pipeline for **local Jupyter** users.\n",
        "\n",
        "## Prerequisites\n",
        "Make sure you have installed the package:\n",
        "```bash\n",
        "pip install -e .\n",
        "```\n",
        "\n",
        "## What this notebook does:\n",
        "1. ðŸ“Š Loads HCP connectome data\n",
        "2. ðŸ”¬ Runs sexual dimorphism analysis\n",
        "3. ðŸ¤– Trains Random Forest classifier\n",
        "4. ðŸ§  Trains EBM (Explainable Boosting Machine)\n",
        "5. ðŸ“ˆ Compares model performance\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path if running from notebooks directory\n",
        "project_root = Path.cwd().parent\n",
        "if project_root.name == \"Brain-Connectome\":\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"âœ… Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n",
        "\n",
        "Load the processed HCP data. If not available, sample data will be created.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try to load real data, fall back to sample data\n",
        "data_path = project_root / \"data\" / \"processed\" / \"full_data.csv\"\n",
        "\n",
        "if data_path.exists():\n",
        "    print(f\"Loading data from {data_path}\")\n",
        "    data = pd.read_csv(data_path)\n",
        "else:\n",
        "    print(\"Creating sample data for demonstration...\")\n",
        "    rng = np.random.default_rng(42)\n",
        "    n_subjects = 200\n",
        "    n_pcs = 60\n",
        "    \n",
        "    data = {\"Subject\": range(1, n_subjects + 1)}\n",
        "    data[\"Gender\"] = rng.choice([\"M\", \"F\"], n_subjects)\n",
        "    \n",
        "    for i in range(1, n_pcs + 1):\n",
        "        if i in [1, 3, 12, 23, 33]:\n",
        "            male_mean = 0.5 if i % 2 == 0 else -0.5\n",
        "            data[f\"Struct_PC{i}\"] = np.where(\n",
        "                np.array(data[\"Gender\"]) == \"M\",\n",
        "                rng.normal(male_mean, 1, n_subjects),\n",
        "                rng.normal(-male_mean, 1, n_subjects)\n",
        "            )\n",
        "        else:\n",
        "            data[f\"Struct_PC{i}\"] = rng.normal(0, 1, n_subjects)\n",
        "    \n",
        "    data = pd.DataFrame(data)\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset: {data.shape[0]} subjects, {data.shape[1]} features\")\n",
        "print(f\"\\nGender distribution:\\n{data['Gender'].value_counts()}\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Sexual Dimorphism Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from brain_connectome.analysis import DimorphismAnalysis\n",
        "\n",
        "# Run analysis\n",
        "analysis = DimorphismAnalysis(data, gender_column=\"Gender\")\n",
        "struct_pcs = [col for col in data.columns if col.startswith(\"Struct_PC\")]\n",
        "results = analysis.analyze(feature_columns=struct_pcs)\n",
        "\n",
        "n_significant = results[\"Significant\"].sum()\n",
        "print(f\"ðŸ”¬ Found {n_significant} significant features (FDR < 0.05)\")\n",
        "\n",
        "# Plot effect sizes\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "top20 = results.head(20)\n",
        "colors = [\"#1f77b4\" if d < 0 else \"#d62728\" for d in top20[\"Cohen_D\"]]\n",
        "ax.barh(range(len(top20)), top20[\"Cohen_D\"].values, color=colors)\n",
        "ax.set_yticks(range(len(top20)))\n",
        "ax.set_yticklabels(top20[\"Feature\"])\n",
        "ax.set_xlabel(\"Cohen's D\")\n",
        "ax.set_title(\"Sexual Dimorphism: Effect Sizes\")\n",
        "ax.axvline(0, color=\"black\", linewidth=0.5)\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Machine Learning Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from brain_connectome.models import ConnectomeRandomForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare data\n",
        "X = data[struct_pcs].values\n",
        "y = (data[\"Gender\"] == \"M\").astype(int).values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "clf = ConnectomeRandomForest(n_estimators=200, random_state=42)\n",
        "clf.fit(X_train, y_train, feature_names=struct_pcs)\n",
        "metrics = clf.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"ðŸŽ¯ Test Accuracy: {metrics['accuracy']:.2%}\")\n",
        "\n",
        "# Plot feature importance\n",
        "importance = clf.get_top_features(n=15)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "top15 = importance.iloc[::-1]\n",
        "ax.barh(top15[\"Feature\"], top15[\"Importance\"], color=plt.colormaps[\"viridis\"](np.linspace(0.3, 0.9, len(top15))))\n",
        "ax.set_xlabel(\"Importance\")\n",
        "ax.set_title(\"Top 15 Features for Classification\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: EBM (Explainable Boosting Machine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from brain_connectome.models import ConnectomeEBM\n",
        "\n",
        "# Train EBM (interpretable model)\n",
        "ebm = ConnectomeEBM(learning_rate=0.01, max_bins=32, max_leaves=3, interactions=0, random_state=42)\n",
        "ebm.fit(X_train, y_train, feature_names=struct_pcs)\n",
        "ebm_metrics = ebm.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"ðŸŽ¯ EBM Accuracy: {ebm_metrics['accuracy']:.2%}\")\n",
        "print(f\"ðŸ“Š Random Forest: {metrics['accuracy']:.2%}\")\n",
        "\n",
        "# Compare top features\n",
        "ebm_importance = ebm.get_top_features(n=10)\n",
        "print(\"\\nEBM Top Features:\")\n",
        "print(ebm_importance.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Analysis complete! For the full pipeline with PCA and VAE, run:\n",
        "```bash\n",
        "python Runners/run_pipeline.py\n",
        "```\n",
        "\n",
        "Or use Docker:\n",
        "```bash\n",
        "docker run -v $(pwd)/data:/app/data -v $(pwd)/output:/app/output ghcr.io/sean0418/brain-connectome:latest\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
