{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc25ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from interpret import show\n",
    "\n",
    "MODEL_DIR = \"models\"  # adjust if needed\n",
    "\n",
    "def load_ebm(sex: str, variant: str, model_dir: str = MODEL_DIR):\n",
    "    \"\"\"\n",
    "    Load a saved EBM model (possibly wrapped in a pipeline) and return\n",
    "    the ExplainableBoostingClassifier object.\n",
    "    \"\"\"\n",
    "    model_path = os.path.join(model_dir, f\"ebm_{sex}_{variant}.pkl\")\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "\n",
    "    obj = joblib.load(model_path)\n",
    "\n",
    "    # Your saving format was {\"model\": pipeline_or_ebm, \"features\": [...]}\n",
    "    if isinstance(obj, dict):\n",
    "        pipe = obj[\"model\"]\n",
    "    else:\n",
    "        pipe = obj\n",
    "\n",
    "    # If it's an imblearn/sklearn pipeline with a \"model\" step, extract EBM\n",
    "    if hasattr(pipe, \"named_steps\") and \"model\" in pipe.named_steps:\n",
    "        ebm = pipe.named_steps[\"model\"]\n",
    "    else:\n",
    "        ebm = pipe\n",
    "\n",
    "    return ebm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: men, TN-PCA combined model\n",
    "sex = \"M\"\n",
    "variant = \"tnpca\"   # or \"pca\", \"cog_only\", \"tnpca_only\", etc.\n",
    "\n",
    "ebm_model = load_ebm(sex, variant)\n",
    "expl = ebm_model.explain_global(name=f\"{sex}-{variant}\")\n",
    "show(expl)  # this is the interpret dashboard as notebook output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcp_ebm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
